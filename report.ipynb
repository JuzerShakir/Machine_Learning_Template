{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: _Project Name_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Type of ML project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Table of Contents\n",
    "\n",
    "- [Getting Started](#Getting-Started)\n",
    "    - [Feature Statistics](#Feature-Statistics)\n",
    "        - [Feature Describe](#Feature-Describe)\n",
    "        - [Feature Skew](#Feature-Skew)\n",
    "        - [Class Distribution](#Class-Distribution)\n",
    "    - [Feature Visualization](#Feature-Visualization)\n",
    "        - [Feature Spread](#Feature-Spread)\n",
    "        - [Feature Distribution](#Feature-Distribution)\n",
    "        - [Feature Comparison](#Feature-Comparison)\n",
    "        - [Feature Correlation](#Feature-Correlation)       \n",
    "- [Data Engineering](#Data-Engineering)\n",
    "    - [Observation Cleaning](#Observation-Cleaning)\n",
    "        - [Handling Missing Values](#Handling-Missing-Values)\n",
    "        - [Handling Duplicates](#Handling-Duplicates)\n",
    "    - [Dimentionality Reduction](#Dimentionality-Reduction)\n",
    "        - [Extra-Trees Classifier](#Extra-Trees-Classifier)\n",
    "        - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "        - [AdaBoost Classifier](#AdaBoost-Classifier)\n",
    "        - [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    - [Feature Scaling](#Feature-Scaling)\n",
    "    - [Train-Test Split](#Train-Test-Split)\n",
    "- [Model Evaluations](#Model-Evaluations)\n",
    "    - [Model 1](#Model-1)\n",
    "    - [Model 2](#Model-2)\n",
    "    - [Model 3](#Model-3)\n",
    "    - [Model 4](#Model-4)\n",
    "    - [Model 5](#Model-5)\n",
    "    - [Model 6](#Model-6)\n",
    "- [Testing Model](#Testing-Model)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [Notes](#Notes)\n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "_Giving necessory, important and short info on this project._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Check-In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for the project\n",
    "import sys # for python library version\n",
    "import numpy as np # for scientific computing\n",
    "import pandas as pd # for data anaysis\n",
    "import matplotlib # for visualization\n",
    "import seaborn as sns # for visualization\n",
    "import sklearn # ML Library\n",
    "import tensorflow as tf # deep learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python: {}'.format(sys.version))  # Python version\n",
    "print('numpy: {}'.format(np.__version__))  # Numpy version\n",
    "print('pandas: {}'.format(pd.__version__))  # Pandas version\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))  # Matplotlib version\n",
    "print('seaborn: {}'.format(sns.__version__))  # seaborn version\n",
    "print('sklearn: {}'.format(sklearn.__version__))  # sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No warning of any kind please!\n",
    "import warnings\n",
    "# will ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Feature Statistics\n",
    "\n",
    "#### Feature Describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution\n",
    "\n",
    "Let's take a look how each class is distributed.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra-Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# passing the model\n",
    "model = ExtraTreesClassifier(random_state = 53)\n",
    "\n",
    "# feeding all our features to var 'X'\n",
    "X = data.iloc[:,:-1]\n",
    "# feeding our target variable to var 'y'\n",
    "y = data['']\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "ETC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ETC']).sort_values('ETC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "ETC_feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# passing the model\n",
    "model = RandomForestClassifier(random_state = 53)\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "RFC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['RFC']).sort_values('RFC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "RFC_feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# passing the model\n",
    "model = AdaBoostClassifier(random_state = 53)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "ADB_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ADB']).sort_values('ADB', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "ADB_feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# passing the model\n",
    "model = GradientBoostingClassifier(random_state = 53)\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "GBC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['GBC']).sort_values('GBC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "GBC_feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining function for training models and measuring performance \n",
    "\n",
    "# to measure performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# for calculating time elapsed\n",
    "import time\n",
    "\n",
    "# fucntion\n",
    "def model_evaluation(clf):\n",
    "    \n",
    "    # passing classifier to a variable\n",
    "    clf = clf\n",
    "    \n",
    "    # records time\n",
    "    t_start = time.time()\n",
    "    # classifier learning the model\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    # records time\n",
    "    t_end = time.time()\n",
    "    \n",
    "    \n",
    "    # records time\n",
    "    c_start = time.time()     \n",
    "    # Using 10 K-Fold CV on data, gives peroformance measures\n",
    "    accuracy  = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    f1_score = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'f1_macro')\n",
    "    # records the time\n",
    "    c_end = time.time()    \n",
    "    \n",
    "    \n",
    "    # calculating mean of all 10 observation's accuracy and f1, taking percent and rounding to two decimal places\n",
    "    acc_mean = np.round(accuracy.mean() * 100, 2)\n",
    "    f1_mean = np.round(f1_score.mean() * 100, 2)\n",
    "    \n",
    "    \n",
    "    # substracts end time with start to give actual time taken in seconds\n",
    "    # divides by 60 to convert in minutes and rounds the answer to three decimal places\n",
    "    # time in training\n",
    "    t_time = np.round((t_end - t_start) / 60, 3)\n",
    "    # time for evaluating scores\n",
    "    c_time = np.round((c_end - c_start) / 60, 3)\n",
    "    \n",
    "    \n",
    "    # Removing traces of classifier\n",
    "    clf = None\n",
    "    \n",
    "    \n",
    "    # returns performance measure and time of the classifier \n",
    "    print(\"The accuracy score of this classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train and\", c_time,\n",
    "          \"minutes to evaluate cross validation and metric scores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Model\n",
    "\n",
    "Out of 6 Models evaluated above and benchmark model, which performs better? Lets see all the scores of all the models in a table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Accuracy | F1 Score | Train Time (m) | Evaluation Time (m) |\n",
    "| ----- | -------- | -------- | ---------- | --------------- |\n",
    "|  |  |  |  |  |\n",
    "|  |  |  |  |  |\n",
    "|  |  |  |  |  |\n",
    "|  |  |  |  |  |\n",
    "|  |  |  |  |  |\n",
    "|  |  |  |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing EM scores for model performance measure\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# definning best chosen classifier\n",
    "clf = RandomForestClassifier(n_estimators = 50, random_state = 53)\n",
    "\n",
    "# training our model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# predicting unseen data\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "# calculating f1 score\n",
    "f1_score = f1_score(y_test, predict, average = 'macro')\n",
    "\n",
    "# taking precentage and rounding to 3 places\n",
    "accuracy = np.round(accuracy * 100, 3)\n",
    "f1_score = np.round(f1_score * 100, 3)\n",
    "\n",
    "# cleaning traces\n",
    "clf = None\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of our final model Random Forest Classifier on our testing set is\", accuracy,\"% and f1 score is\", f1_score,\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
